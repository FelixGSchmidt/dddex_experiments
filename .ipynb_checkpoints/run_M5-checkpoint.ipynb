{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b87ed0-3df6-4b0b-8ea7-3869bcbc2d37",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503d9fae-c502-4d23-bbf7-6da631b5ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from dddex.levelSetKDEx_univariate import LevelSetKDEx, LevelSetKDEx_NN\n",
    "from dddex.wSAA import RandomForestWSAA, SampleAverageApproximation\n",
    "from dddex.crossValidation import QuantileCrossValidation, QuantileCrossValidationLSx, groupedTimeSeriesSplit\n",
    "from dddex.utils import generateFinalOutput\n",
    "# from generalFuncs.runModels import tunePredictSave, getCostsNV\n",
    "# import generalFuncs\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "import re\n",
    "import ipdb\n",
    "import pickle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355fe8c7-c013-4b86-a2bd-666e59f33adb",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991226ba-6a0f-42ed-8bc7-9c799b11e1ea",
   "metadata": {},
   "source": [
    "## Main Function - Tune Predict Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94f32ba-84e1-4460-ae31-d94d1272c6d0",
   "metadata": {},
   "source": [
    "NOTE: decisionArtifact and costArtifact must have been logged already before calling `tunePredictSave`. This is required because of the current\n",
    "way `updateArtifact` is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17f975c8-bd88-42c8-8406-78a5e2b48836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tunePredictSave(quantileEstimator,\n",
    "                    combinedCV,\n",
    "                    model,\n",
    "                    estimatorName):\n",
    "    \n",
    "    runName = model + \"_\" + estimatorName\n",
    "    runName = runName + \"_\" + \"combinedCV\" if combinedCV else runName\n",
    "    runName_SLTuning = runName + \"_SLTuning\"\n",
    "    \n",
    "    config = {'isModellingRun': True,\n",
    "              'model': model,\n",
    "              'estimator': estimatorName,\n",
    "              'weightsByDistance': weightsByDistance,\n",
    "              'combinedCV': combinedCV,\n",
    "              'SLTuning': False,\n",
    "              'kFolds': kFolds,\n",
    "              'nIter': nIter}\n",
    "    \n",
    "    run = wandb.init(project = project, name = runName, job_type = \"modelling\", config = config)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    if combinedCV:\n",
    "        \n",
    "        if estimatorName == 'LGBM':\n",
    "            paramGridEstimator = paramGridLGBM\n",
    "        else:\n",
    "            paramGridEstimator = paramGridRF\n",
    "            \n",
    "        LSxCV = QuantileCrossValidationLSx(estimatorLSx = quantileEstimator, \n",
    "                                           cvFolds = cvFolds,\n",
    "                                           parameterGridLSx = binSizeGrid,\n",
    "                                           parameterGridEstimator = paramGridEstimator,\n",
    "                                           randomSearchEstimator = True,\n",
    "                                           nIterEstimator = nIter,\n",
    "                                           probs = probs,\n",
    "                                           refitPerProb = True,\n",
    "                                           n_jobs = len(cvFolds))\n",
    "        \n",
    "        paramsEstimatorForOutput = {}\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        if model == 'WSAA':\n",
    "            paramGrid = paramGridRF\n",
    "            randomSearch = True\n",
    "            paramsEstimatorForOutput = {}\n",
    "        else:\n",
    "            paramGrid = binSizeGrid\n",
    "            randomSearch = False\n",
    "            \n",
    "            if estimatorName == 'LGBM':\n",
    "                paramsEstimatorForOutput = paramsLGBM\n",
    "            else:\n",
    "                paramsEstimatorForOutput = paramsRF\n",
    "            \n",
    "        LSxCV = QuantileCrossValidation(estimator = quantileEstimator, \n",
    "                                        cvFolds = cvFolds,\n",
    "                                        parameterGrid = paramGrid,\n",
    "                                        randomSearch = randomSearch,\n",
    "                                        nIter = nIter,\n",
    "                                        probs = probs,\n",
    "                                        refitPerProb = True,\n",
    "                                        n_jobs = len(cvFolds))\n",
    "\n",
    "    LSxCV.fit(X = XTrain, \n",
    "              y = yTrain)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    # Results without Service-Level-Tuning\n",
    "    quantilesDf = LSxCV.bestEstimator.predict(X = XTest, \n",
    "                                              probs = probs, \n",
    "                                              outputAsDf = True, \n",
    "                                              scalingList = scalingList)\n",
    "\n",
    "    quantilesDf.columns = colnamesQuantile\n",
    "\n",
    "    resDf = generateFinalOutput(dataOriginal = data, \n",
    "                                dataDecisions = quantilesDf, \n",
    "                                targetVariable = 'demand', \n",
    "                                mergeOn = None, \n",
    "                                variablesToAdd = ['dayIndex', 'scalingValue'], \n",
    "                                scaleBy = 'scalingValue', \n",
    "                                includeTraining = False, \n",
    "                                sortBy = ['id', 'dayIndex'],\n",
    "                                longFormat = True,\n",
    "                                **paramsEstimatorForOutput,\n",
    "                                **LSxCV.bestParams)\n",
    "    \n",
    "    costsPerID, costsPerSL = getCostsNV(resDf = resDf,\n",
    "                                        costsPerID_SAA = costsPerID_SAA)\n",
    "    \n",
    "    wandb.log(costsPerSL)\n",
    "    wandb.finish()\n",
    "    \n",
    "    updateArtifact(name = 'decisionData',\n",
    "                   dataToAdd = resDf,\n",
    "                   fileNameToAdd = runName)\n",
    "    \n",
    "    updateArtifact(name = 'costData',\n",
    "                   dataToAdd = costsPerID,\n",
    "                   fileNameToAdd = runName) \n",
    "    \n",
    "    #---\n",
    "    \n",
    "    # Results with Service-Level-Tuning\n",
    "    config['SLTuning'] = True\n",
    "    run = wandb.init(project = project, name = runName_SLTuning, job_type = \"modelling\", config = config)\n",
    "    \n",
    "    resList = list()\n",
    "\n",
    "    for prob in probs:   \n",
    "\n",
    "        quantilesDf = LSxCV.bestEstimator_perProb[prob].predict(X = XTest, \n",
    "                                                                probs = prob, \n",
    "                                                                outputAsDf = True, \n",
    "                                                                scalingList = scalingList)\n",
    "\n",
    "        quantilesDf.columns = [\"quantile_\" + str(int(prob * 1000))]\n",
    "\n",
    "        resDf_prob = generateFinalOutput(dataOriginal = data,\n",
    "                                         dataDecisions = quantilesDf,\n",
    "                                         targetVariable = 'demand',\n",
    "                                         mergeOn = None,\n",
    "                                         variablesToAdd = ['dayIndex', 'scalingValue'],\n",
    "                                         scaleBy = 'scalingValue',\n",
    "                                         includeTraining = False,\n",
    "                                         longFormat = True,\n",
    "                                         **paramsEstimatorForOutput,\n",
    "                                         **LSxCV.bestParams_perProb[prob])\n",
    "\n",
    "        resList.append(resDf_prob)\n",
    "\n",
    "    resDf_SLTuning = pd.concat(resList, axis = 0)\n",
    "    \n",
    "    costsPerID_SLTuning, costsPerSL_SLTuning = getCostsNV(resDf = resDf_SLTuning,\n",
    "                                                          costsPerID_SAA = costsPerID_SAA)\n",
    "    \n",
    "    wandb.log(costsPerSL_SLTuning)\n",
    "    wandb.finish()\n",
    "    \n",
    "    updateArtifact(name = 'decisionData',\n",
    "                   dataToAdd = resDf_SLTuning,\n",
    "                   fileNameToAdd = runName_SLTuning)\n",
    "    \n",
    "    updateArtifact(name = 'costData',\n",
    "                   dataToAdd = costsPerID_SLTuning,\n",
    "                   fileNameToAdd = runName_SLTuning)  \n",
    "    \n",
    "    # return resDf, costsPerID, costsPerSL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a580fafb-76d3-49f9-a818-b6cfbae35840",
   "metadata": {},
   "source": [
    "## Update Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b3d6a0-733f-44ef-986b-499797df1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateArtifact(name,\n",
    "                   dataToAdd,\n",
    "                   fileNameToAdd,\n",
    "                   alias = 'latest',\n",
    "                   ):\n",
    "\n",
    "    run = wandb.init(project = project, name = 'updateArtifacts', job_type = 'updateArtifact', config = {'isModellingRun': False})\n",
    "    \n",
    "    artifactOld = run.use_artifact(name + ':' + alias)\n",
    "    artifactFolder = artifactOld.download()\n",
    "\n",
    "    fileNames = os.listdir(artifactFolder)\n",
    "\n",
    "    artifactNew = wandb.Artifact(name = name,\n",
    "                                 type = artifactOld.type,\n",
    "                                 description = artifactOld.description,\n",
    "                                 metadata = artifactOld.metadata)\n",
    "\n",
    "    for fileOld in fileNames:\n",
    "        path = os.path.join(artifactFolder, fileOld)\n",
    "\n",
    "        with open(path, 'rb') as file:\n",
    "            dataOld = pd.read_pickle(file)\n",
    "\n",
    "        with artifactNew.new_file(fileOld, mode = \"wb\") as file:\n",
    "            dataOld.to_pickle(file)\n",
    "\n",
    "    with artifactNew.new_file(fileNameToAdd + '.pkl', mode = \"wb\") as file:\n",
    "            dataToAdd.to_pickle(file)\n",
    "\n",
    "    wandb.log_artifact(artifactNew)\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    shutil.rmtree(artifactFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f77320-9358-402a-a2a2-547d9ab287a0",
   "metadata": {},
   "source": [
    "## Load Current Data To Continue after Break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9110a617-94df-400d-8719-73ff9628752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataToContinue():\n",
    "    \n",
    "    global costsPerID_SAA\n",
    "    global estimatorLGBM\n",
    "    global estimatorRF\n",
    "    global paramsLGBM\n",
    "    global paramsRF\n",
    "    global data\n",
    "    global XTrain\n",
    "    global yTrain\n",
    "    global XTest\n",
    "    global yTest\n",
    "    global scalingList\n",
    "    global nIter\n",
    "    global kFolds\n",
    "    global probs\n",
    "    global colnamesQuantile\n",
    "    global cvFolds\n",
    "    global binSizeGrid\n",
    "    global paramGridLGBM\n",
    "    global paramGridRF\n",
    "    global paramGridRF_LGBM\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    run = wandb.init(project = project, name = \"loadDataToContinue\", job_type = \"loadData\", config = {'isModellingRun': False})\n",
    "    \n",
    "    #---\n",
    "\n",
    "    artifactPredictorData = run.use_artifact('predictorData:latest')\n",
    "    predictorDataFolder = artifactPredictorData.download()\n",
    "\n",
    "    pathParamsLGBM = os.path.join(predictorDataFolder, \"paramsLGBM.pkl\")\n",
    "    with open(pathParamsLGBM, 'rb') as file:\n",
    "        paramsLGBM = pickle.load(file)\n",
    "        \n",
    "    pathParamsRF = os.path.join(predictorDataFolder, \"paramsRF.pkl\")\n",
    "    with open(pathParamsRF, 'rb') as file:\n",
    "        paramsRF = pickle.load(file)\n",
    "\n",
    "    pathEstimatorLGBM = os.path.join(predictorDataFolder, \"LGBM.pkl\")\n",
    "    with open(pathEstimatorLGBM, 'rb') as file:\n",
    "        estimatorLGBM = pickle.load(file)\n",
    "\n",
    "    pathEstimatorRF = os.path.join(predictorDataFolder, \"RF.pkl\")\n",
    "    with open(pathEstimatorRF, 'rb') as file:\n",
    "        estimatorRF = pickle.load(file)\n",
    "        \n",
    "    shutil.rmtree(predictorDataFolder)\n",
    "\n",
    "    #---\n",
    "\n",
    "    artifactCosts = run.use_artifact('costData:latest')\n",
    "    costsDataFolder = artifactCosts.download()\n",
    "\n",
    "    pathCostsSAA = os.path.join(costsDataFolder, \"SAA.pkl\")\n",
    "    costsPerID_SAA = pd.read_pickle(pathCostsSAA)\n",
    "    \n",
    "    shutil.rmtree(costsDataFolder)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    artifactModelData = run.use_artifact('modelData:latest')\n",
    "    modelDataFolder = artifactModelData.download()\n",
    "    \n",
    "    pathData = os.path.join(modelDataFolder, \"data.pkl\")\n",
    "    data = np.load(pathData, allow_pickle = True)\n",
    "    scalingList = data['scalingValue'][data['label'] == 'test'].to_list()\n",
    "    \n",
    "    filesToLoad = [\"XTrain\", \"yTrain\", \"XTest\", \"yTest\"]\n",
    "    \n",
    "    fileDictModelData = {}\n",
    "    for fileName in filesToLoad:\n",
    "        pathFile = os.path.join(modelDataFolder, fileName + \".pkl\")\n",
    "        fileDictModelData[fileName] = np.load(pathFile, allow_pickle = True)\n",
    "    \n",
    "    XTrain = fileDictModelData[\"XTrain\"]\n",
    "    yTrain = fileDictModelData[\"yTrain\"]\n",
    "    XTest = fileDictModelData[\"XTest\"]\n",
    "    yTest = fileDictModelData[\"yTest\"]\n",
    "    \n",
    "    shutil.rmtree(modelDataFolder)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    artifactCVData = run.use_artifact('cvData:latest')\n",
    "    cvDataFolder = artifactCVData.download()\n",
    "    \n",
    "    filesToLoad = [\"cvHyperParameters\", \"probs\", \"colnamesQuantile\", \"cvFolds\", \"binSizeGrid\", \"paramGridLGBM\", \"paramGridRF\", \"paramGridRF_LGBM\"]\n",
    "    \n",
    "    fileDictCV = {}\n",
    "    for fileName in filesToLoad:\n",
    "        pathFile = os.path.join(cvDataFolder, fileName + \".pkl\")\n",
    "        \n",
    "        with open(pathFile, 'rb') as file:\n",
    "            fileDictCV[fileName] = pickle.load(file)        \n",
    "    \n",
    "    nIter = fileDictCV[\"cvHyperParameters\"][\"nIter\"]\n",
    "    kFolds = fileDictCV[\"cvHyperParameters\"][\"kFolds\"]\n",
    "    probs = fileDictCV[\"probs\"]\n",
    "    colnamesQuantile = fileDictCV[\"colnamesQuantile\"]\n",
    "    cvFolds = fileDictCV[\"cvFolds\"]\n",
    "    binSizeGrid = fileDictCV[\"binSizeGrid\"]\n",
    "    paramGridLGBM = fileDictCV[\"paramGridLGBM\"]\n",
    "    paramGridRF = fileDictCV[\"paramGridRF\"]\n",
    "    paramGridRF_LGBM = fileDictCV[\"paramGridRF_LGBM\"]\n",
    "    \n",
    "    shutil.rmtree(cvDataFolder)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c0ab8-155a-493b-9f38-356a8555830b",
   "metadata": {},
   "source": [
    "## Get Newsvendor Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf18d2f-922f-4bcc-8c41-19fed794d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCostsNV(resDf,\n",
    "               costsPerID_SAA = None):\n",
    "    \n",
    "    serviceLevels = np.array([int(re.findall('[0-9]+', decisionType)[0]) / 1000 for decisionType in resDf['decisionType']])\n",
    "    # serviceLevels = resDf['decisionType'] * 10\n",
    "    \n",
    "    errors = resDf['actuals'] - resDf['decisions']\n",
    "    resDf['costs'] = np.where(errors >= 0, errors * serviceLevels, np.abs(errors) * (1 - serviceLevels))\n",
    "\n",
    "    costsPerID = resDf.groupby(['id', 'decisionType'], sort = False)['costs'].sum()\n",
    "    \n",
    "    if not costsPerID_SAA is None:\n",
    "        costsPerID = costsPerID / costsPerID_SAA\n",
    "    \n",
    "    costsPerSL = costsPerID.reset_index().groupby(['decisionType'], sort = False)['costs'].mean()\n",
    "    costsPerSL = costsPerSL.to_dict()\n",
    "    \n",
    "    return costsPerID, costsPerSL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb50a52-93d6-4afa-9e05-0960fe3f5bb3",
   "metadata": {},
   "source": [
    "# Setup Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3a4312-99e1-45f9-a420-7c8f1f9a8cd7",
   "metadata": {},
   "source": [
    "## Weights & Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36054dc-6a4f-4ab3-a167-887d9f7bedc6",
   "metadata": {},
   "source": [
    "### Environment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2b505a4-2d61-4ffe-b458-6b163b98cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'run_M5.ipynb'\n",
    "os.environ['WANDB_SILENT'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aca53c1-717d-4e78-a2ce-f4fbade32204",
   "metadata": {},
   "source": [
    "### Project Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4de56008-f57d-4f4f-a31f-c6b2025b353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'modellingM5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5987a5-a13b-4586-8f7a-41d0a8df5ed2",
   "metadata": {},
   "source": [
    "### Load and Save Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e97b447-c4b4-48aa-b4c9-21b6d93cfe96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/d3wue/modellingM5/runs/3o1xfygm?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f46f6b57ac0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'isModellingRun': False}\n",
    "\n",
    "wandb.init(project = project, name = 'loadModelData', job_type = 'loadData', config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffe9c86d-137e-4d85-a4dc-211987b98589",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/kagu/M5/data/dataM5.csv'\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# ids = data.id.unique()[0:2]\n",
    "# filtering = [ID in ids for ID in data.id]\n",
    "# data = data[filtering]\n",
    "\n",
    "X = np.array(data.drop(['demand', 'id', 'label'], axis = 1))\n",
    "Y = np.array(data['demand'])\n",
    "\n",
    "indicesTrain = data['label'] == 'train'\n",
    "indicesTest = data['label'] == 'test'\n",
    "\n",
    "XTrain = X[indicesTrain]\n",
    "yTrain = Y[indicesTrain]\n",
    "\n",
    "XTest = X[indicesTest]\n",
    "yTest = Y[indicesTest]\n",
    "\n",
    "dataTrain = data[indicesTrain]\n",
    "dataTest = data[indicesTest]\n",
    "\n",
    "scalingList = dataTest['scalingValue'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84dafe8e-acf8-40e2-a666-648b899825ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "testLength = sum(data[data.id == data.id[0]].label == 'test')\n",
    "numberOfIDs = len(data['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fa1c8af-da86-46c9-9412-006758154ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f46f6a917f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelData = wandb.Artifact(name = \"modelData\", \n",
    "                           type = \"dataset\",\n",
    "                           description = \"Train/Test data used for modelling\",\n",
    "                           metadata = {\"testLength\": testLength,\n",
    "                                       \"numberOfIDs\": numberOfIDs})\n",
    "\n",
    "with modelData.new_file(\"data.pkl\", mode = \"wb\") as file:\n",
    "    data.to_pickle(file)\n",
    "\n",
    "datasets = [XTrain, yTrain, XTest, yTest]\n",
    "names = [\"XTrain\", \"yTrain\", \"XTest\", \"yTest\"]\n",
    "\n",
    "for name, dataset in zip(names, datasets):\n",
    "    with modelData.new_file(name + \".pkl\", mode = \"wb\") as file:\n",
    "        np.save(file, dataset)      \n",
    "    \n",
    "wandb.log_artifact(modelData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e2bb6e-fe7e-4d2b-8d5c-25d28d3ad33b",
   "metadata": {},
   "source": [
    "### Set and Save Cross Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bd26361-6c6c-4141-a40c-c1822c7db0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/d3wue/modellingM5/runs/2egm7l13?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f46f6a84b50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'isModellingRun': False}\n",
    "\n",
    "wandb.init(project = project, name = 'crossValidationData', job_type = 'setCVData', config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4119dfba-3561-4fd7-b5a6-2a08a0bb3e55",
   "metadata": {},
   "source": [
    "#### Probs of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5ca8353-9582-4627-bbef-395587effba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.005, 0.01 , 0.02 , 0.025, 0.03 , 0.04 , 0.05 , 0.06 , 0.07 ,\n",
       "       0.08 , 0.09 , 0.1  , 0.11 , 0.12 , 0.13 , 0.14 , 0.15 , 0.16 ,\n",
       "       0.165, 0.17 , 0.18 , 0.19 , 0.2  , 0.21 , 0.22 , 0.23 , 0.24 ,\n",
       "       0.25 , 0.26 , 0.27 , 0.28 , 0.29 , 0.3  , 0.31 , 0.32 , 0.33 ,\n",
       "       0.34 , 0.35 , 0.36 , 0.37 , 0.38 , 0.39 , 0.4  , 0.41 , 0.42 ,\n",
       "       0.43 , 0.44 , 0.45 , 0.46 , 0.47 , 0.48 , 0.49 , 0.5  , 0.51 ,\n",
       "       0.52 , 0.53 , 0.54 , 0.55 , 0.56 , 0.57 , 0.58 , 0.59 , 0.6  ,\n",
       "       0.61 , 0.62 , 0.63 , 0.64 , 0.65 , 0.66 , 0.67 , 0.68 , 0.69 ,\n",
       "       0.7  , 0.71 , 0.72 , 0.73 , 0.74 , 0.75 , 0.76 , 0.77 , 0.78 ,\n",
       "       0.79 , 0.8  , 0.81 , 0.82 , 0.83 , 0.835, 0.84 , 0.85 , 0.86 ,\n",
       "       0.87 , 0.88 , 0.89 , 0.9  , 0.91 , 0.92 , 0.93 , 0.94 , 0.95 ,\n",
       "       0.96 , 0.97 , 0.975, 0.98 , 0.99 , 0.995])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = np.concatenate([np.array([0.005, 0.025, 0.165, 0.835, 0.975, 0.995]), np.arange(1, 100, 1) / 100])\n",
    "probs = np.sort(probs)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "765213bd-4cd0-484a-adf5-2841bf9694c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "probsPermille = np.around(probs * 1000, decimals = 0)\n",
    "probsName = [str(int(i)) for i in iter(probsPermille)]\n",
    "\n",
    "colnamesQuantile = ['quantile_{}'.format(i) for i in iter(probsName)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0782c6-3070-4cc6-af61-7f0a3456ef2a",
   "metadata": {},
   "source": [
    "#### CV Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1250f56a-e2d5-4029-8e9a-40d8d6ace3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nIter = 120\n",
    "kFolds = 4\n",
    "\n",
    "cvHyperParameters = {\"nIter\": nIter,\n",
    "                     \"kFolds\": kFolds}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25150f15-445c-4a96-bceb-55c78e51fab5",
   "metadata": {},
   "source": [
    "#### Cross Validation Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9c8e2a5-34ae-4809-81d6-f0fe23390267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Split\n",
    "cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "                                 kFolds = kFolds, \n",
    "                                 testLength = testLength, \n",
    "                                 groupFeature = 'id', \n",
    "                                 timeFeature = 'dayIndex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e05368c-a0b6-4426-b260-1fd509bd3799",
   "metadata": {},
   "source": [
    "#### Param Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f614bff-7d2a-48b1-bd26-67ecacf58d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGridLGBM = {'num_leaves': [10, 25, 40, 60, 80, 100, 150, 200, 250, 300],\n",
    "                 'max_depth': [-1, 3, 4, 5, 6, 7],\n",
    "                 'min_child_samples': [10, 30, 50, 75, 100, 150, 250, 400, 600, 800, 1000, 1500, 2000, 3000, 5000, 10000],\n",
    "                 'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
    "                 'n_estimators': [100, 200, 300, 400, 500, 600],\n",
    "                 'subsample': [0.05, 0.1, 0.2, 0.3, 0.5, 0.75, 1],\n",
    "                 'colsample_bytree': [0.05, 0.1, 0.2, 0.3, 0.5, 0.75, 1]}\n",
    "\n",
    "paramGridRF_LGBM = {'max_depth': [-1, 2, 3, 4, 5, 6, 7],\n",
    "                    'min_child_samples': [10, 30, 50, 75, 100, 150, 250, 400, 600, 800, 1000, 1500, 2000, 3000, 5000, 10000],\n",
    "                    'n_estimators': [100, 150, 200, 250, 300, 400, 500, 600],\n",
    "                    'subsample': [0.1, 0.3, 0.5, 0.75],\n",
    "                    'subsample_freq' : [1],\n",
    "                    'colsample_bytree': [0.1, 0.3, 0.5, 0.75, 1]}\n",
    "\n",
    "paramGridRF = [{'max_depth': [2, 3, 4, 5, 6, 7, 8, 10],\n",
    "               'min_samples_leaf': [10, 30, 50, 75, 100, 150, 250, 400, 600, 800, 1000, 1500, 2000, 3000, 5000, 10000],\n",
    "               'max_features': [0.1, 0.3, 0.5, 0.75, 1],\n",
    "               'n_estimators': [100, 150, 200, 250, 300, 400, 500, 600],\n",
    "               'max_samples': [0.1, 0.3, 0.5, 0.75, 1],\n",
    "               'bootstrap' : [True]},\n",
    "               {'max_depth': [2, 3, 4, 5, 6, 7, 8, 10],\n",
    "               'min_samples_leaf': [10, 30, 50, 75, 100, 150, 250, 400, 600, 800, 1000, 1500, 2000, 3000, 5000, 10000],\n",
    "               'max_features': [0.1, 0.3, 0.5, 0.75, 1],\n",
    "               'n_estimators': [100, 150, 200, 250, 300, 400, 500, 600],\n",
    "               'max_samples': [None],\n",
    "               'bootstrap' : [False]}]\n",
    "               \n",
    "\n",
    "#---\n",
    "\n",
    "binSizeGrid = {'binSize': [200, 300, 400, 500, 750, 1000, \n",
    "                           1500, 2000, 2500, 3000, \n",
    "                           4000, 5000, 6000, \n",
    "                           8000, 10000]}\n",
    "\n",
    "# binSizeGrid = {'binSize': [200, 750, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6011c303-fe7c-4e85-ab94-c2cc3b1de876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f46f6812310>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvData = wandb.Artifact(name = \"cvData\", \n",
    "                        type = \"model\",\n",
    "                        description = \"Cross-Validation Data - Contains Param Grids and Folds\")\n",
    "\n",
    "grids = [probs, colnamesQuantile, cvHyperParameters, cvFolds, paramGridLGBM, paramGridRF_LGBM, paramGridRF, binSizeGrid]\n",
    "names = [\"probs\", \"colnamesQuantile\", \"cvHyperParameters\", \"cvFolds\", \"paramGridLGBM\", \"paramGridRF_LGBM\", \"paramGridRF\", \"binSizeGrid\"]\n",
    "\n",
    "for name, grid in zip(names, grids):\n",
    "    with cvData.new_file(name + \".pkl\", mode = \"wb\") as file:\n",
    "        pickle.dump(grid, file)\n",
    "        \n",
    "wandb.log_artifact(cvData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399cb4f-8a3f-4159-809c-a20bb3228401",
   "metadata": {},
   "source": [
    "### Additional Artifacts Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78f4e70e-448f-41db-8791-e7babe81a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionArtifact = wandb.Artifact(name = \"decisionData\", \n",
    "                                  type = \"decisions\",\n",
    "                                  description = \"Test decisions for all models\",\n",
    "                                  metadata = {\"testLength\": testLength,\n",
    "                                              \"numberOfIDs\": numberOfIDs})\n",
    "\n",
    "costArtifact = wandb.Artifact(name = \"costData\", \n",
    "                              type = \"costs\",\n",
    "                              description = \"Costs per id for all models\",\n",
    "                              metadata = {\"testLength\": testLength,\n",
    "                                          \"numberOfIDs\": numberOfIDs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ca3e9f-6e70-42bf-a886-c9adb2c1fa6b",
   "metadata": {},
   "source": [
    "# Tune Point Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f8ef08-5084-42de-aaa4-b0346cd68ec4",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4ac743e-298f-4cbd-a4b3-9ea35e3c98c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/d3wue/modellingM5/runs/2rucmnbi?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f46f67d64c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'isModellingRun': False,\n",
    "          'estimator': 'LGBM',\n",
    "          'kFolds': kFolds,\n",
    "          'nIter': nIter}\n",
    "\n",
    "wandb.init(project = project, name = \"tuneLGBM\", job_type = \"tuneModels\", config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c67bbe5-c2f3-4d52-8005-7188859bc5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressor\n",
    "estimator = LGBMRegressor(n_jobs = 1)\n",
    "\n",
    "# Cross Validation\n",
    "paramSearch = RandomizedSearchCV(estimator = estimator,\n",
    "                                 cv = cvFolds,\n",
    "                                 n_iter = nIter,\n",
    "                                 param_distributions = paramGridLGBM,\n",
    "                                 scoring = 'neg_mean_squared_error',\n",
    "                                 refit = True,\n",
    "                                 return_train_score = True,\n",
    "                                 n_jobs = 10,\n",
    "                                 random_state = 4444,\n",
    "                                 verbose = 0)\n",
    "\n",
    "paramSearch.fit(X = XTrain,\n",
    "                y = yTrain)\n",
    "\n",
    "estimatorLGBM = paramSearch.best_estimator_\n",
    "paramsLGBM = paramSearch.best_params_\n",
    "        \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b30c89-c1a1-4cc8-b2e8-127af07e0d96",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53d55c31-da10-49bd-80d1-97575dd7103b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/d3wue/modellingM5/runs/1bnlbkdi?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f46f676ed30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'isModellingRun': False,\n",
    "          'estimator': 'RF',\n",
    "          'kFolds': kFolds,\n",
    "          'nIter': nIter}\n",
    "\n",
    "wandb.init(project = project, name = \"tuneRF\", job_type = \"tuneModels\", config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "583d5be9-7bcc-4075-8296-5533d371f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressor\n",
    "estimator = RandomForestRegressor(n_jobs = 1)\n",
    "\n",
    "# Cross Validation\n",
    "paramSearch = RandomizedSearchCV(estimator = estimator,\n",
    "                                 cv = cvFolds,\n",
    "                                 n_iter = nIter,\n",
    "                                 param_distributions = paramGridRF,\n",
    "                                 scoring = 'neg_mean_squared_error',\n",
    "                                 refit = True,\n",
    "                                 return_train_score = True,\n",
    "                                 n_jobs = 10,\n",
    "                                 random_state = 4444,\n",
    "                                 verbose = 0)\n",
    "\n",
    "paramSearch.fit(X = XTrain,\n",
    "                y = yTrain)\n",
    "\n",
    "estimatorRF = paramSearch.best_estimator_\n",
    "paramsRF = paramSearch.best_params_\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51148d62-babf-404b-a504-55834c95374b",
   "metadata": {},
   "source": [
    "## Save Models + Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b152f5d8-fa9b-482f-addf-d4c984b5edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'isModellingRun': False,\n",
    "          'kFolds': kFolds,\n",
    "          'nIter': nIter}\n",
    "\n",
    "wandb.init(project = project, name = 'saveTunedPredictors', job_type = 'saveData', config = config)\n",
    "\n",
    "predictorData = wandb.Artifact(name = \"predictorData\", \n",
    "                               type = \"model\",\n",
    "                               description = \"Tuned and fitted point predictor models and their parameters.\")\n",
    "\n",
    "with predictorData.new_file(\"LGBM.pkl\", mode = \"wb\") as file:\n",
    "    pickle.dump(estimatorLGBM, file)\n",
    "    \n",
    "with predictorData.new_file(\"RF.pkl\", mode = \"wb\") as file:\n",
    "    pickle.dump(estimatorRF, file)\n",
    "    \n",
    "with predictorData.new_file(\"paramsLGBM.pkl\", mode = \"wb\") as file:\n",
    "    pickle.dump(paramsLGBM, file)\n",
    "        \n",
    "with predictorData.new_file(\"paramsRF.pkl\", mode = \"wb\") as file:\n",
    "    pickle.dump(paramsRF, file)\n",
    "    \n",
    "wandb.log_artifact(predictorData)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ea98a5-2a5c-4e94-8087-963c7039c30a",
   "metadata": {},
   "source": [
    "# Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb89e96-aaba-48bb-b497-af5db380d5dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SAA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5456df93-0d23-4123-abdd-c20350bfa8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/d3wue/modellingM5/runs/1pfqquwx?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f46f63766a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'isModellingRun': True,\n",
    "          'model': 'SAA',\n",
    "          'kFolds': kFolds,\n",
    "          'nIter': nIter}\n",
    "\n",
    "wandb.init(project = project, name = \"SAA\", job_type = \"modelling\", config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9c6df00-1972-422d-b3fb-111edb09a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = data['id'].unique()\n",
    "\n",
    "dataResultsList = list()\n",
    "\n",
    "for ID in IDs:\n",
    "    data_id = data[data['id'] == ID]\n",
    "    \n",
    "    y_id = np.array(data_id['demand'])\n",
    "    X_id = np.array(data_id.drop(['demand', 'id', 'label'], axis = 1))\n",
    "    \n",
    "    indicesTrain_id = data_id['label'] == 'train'\n",
    "    indicesTest_id = data_id['label'] == 'test'\n",
    "    \n",
    "    yTrain_id = y_id[indicesTrain_id]\n",
    "    XTrain_id = X_id[indicesTrain_id]\n",
    "\n",
    "    yTest_id = y_id[indicesTest_id]\n",
    "    XTest_id = X_id[indicesTest_id]\n",
    "    \n",
    "    scalingList_id = data_id[indicesTest_id]['scalingValue'].tolist()\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    SAA_id = SampleAverageApproximation()\n",
    "    SAA_id.fit(y = yTrain_id)\n",
    "    \n",
    "    quantilesDfOneOb = SAA_id.predict(X = None, probs = probs, outputAsDf = True, scalingList = scalingList_id)\n",
    "    quantilesDf_id = pd.concat([quantilesDfOneOb] * XTest_id.shape[0], axis = 0).reset_index(drop = True)\n",
    "    quantilesDf_id.columns = colnamesQuantile\n",
    "    \n",
    "    resDf_id = generateFinalOutput(dataOriginal = data_id, \n",
    "                                   dataDecisions = quantilesDf_id, \n",
    "                                   targetVariable = 'demand', \n",
    "                                   mergeOn = None, \n",
    "                                   variablesToAdd = ['dayIndex', 'scalingValue'], \n",
    "                                   scaleBy = 'scalingValue', \n",
    "                                   includeTraining = False, \n",
    "                                   sortBy = ['id', 'dayIndex'],\n",
    "                                   longFormat = True)\n",
    "     \n",
    "    dataResultsList.append(resDf_id)\n",
    "    \n",
    "#---\n",
    "\n",
    "resDf = pd.concat(dataResultsList, axis = 0).reset_index(drop = True)\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f824533f-7bc7-468b-8fe8-7aa851cd74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "costsPerID_SAA, costsPerSL_SAA = getCostsNV(resDf = resDf)\n",
    "\n",
    "# We need to reuse costsPerSL_SAA later on to compute the other cost ratios\n",
    "costsPerSL_SAA = pd.Series(costsPerSL_SAA)\n",
    "\n",
    "costsRatioPerSL_SAA = {decisionType: 1 for decisionType in costsPerSL_SAA.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b438ff78-822f-4d14-96ae-9c5d2c419b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.log({'costsPerSL': wandb.Table(data = pd.DataFrame([costsRatioPerSL_SAA]))})\n",
    "wandb.log(costsRatioPerSL_SAA)\n",
    "\n",
    "with decisionArtifact.new_file(\"SAA.pkl\", mode = \"wb\") as file:\n",
    "    resDf.to_pickle(file)\n",
    "    \n",
    "with costArtifact.new_file(\"SAA.pkl\", mode = \"wb\") as file:\n",
    "    costsPerID_SAA.to_pickle(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd0171-7e69-4fe0-bd8d-63e6307231e5",
   "metadata": {},
   "source": [
    "The next step is necessary to be able to resume computation at any given point without rerunning SAA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d87cf607-fc5f-4814-ada5-4b867d010cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# costsSAA = wandb.Artifact(name = \"costsSAA\", \n",
    "#                           type = \"dataset\",\n",
    "#                           description = \"Costs per ID of SAA (fitted per ID)\")\n",
    "\n",
    "# with costsSAA.new_file(\"costsPerID_SAA.pkl\", mode = \"wb\") as file:\n",
    "#     costsPerID_SAA.to_pickle(file)\n",
    "\n",
    "# wandb.log_artifact(costsSAA)\n",
    "    \n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f6d7a-abcf-4f48-a5af-df002c29df21",
   "metadata": {},
   "source": [
    "## SAA Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e888018f-2c5d-4831-af71-7da2fccd5e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/d3wue/modellingM5/runs/26vct3hb?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f46f633e580>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'isModellingRun': True,\n",
    "          'model': 'SAA_global',\n",
    "          'kFolds': kFolds,\n",
    "          'nIter': nIter}\n",
    "\n",
    "wandb.init(project = project, name = \"SAA_global\", job_type = \"modelling\", config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a88fd7a-1bb3-4aab-8fd6-4ec38435e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAA_global = SampleAverageApproximation()\n",
    "SAA_global.fit(y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec6e0903-7c4b-4c6c-b3ca-f64a76b600b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantilesDfOneOb = SAA_global.predict(X = None, probs = probs, outputAsDf = True, scalingList = None)\n",
    "\n",
    "quantilesDf = pd.concat([quantilesDfOneOb] * XTest.shape[0], axis = 0).reset_index(drop = True)\n",
    "quantilesDf.columns = colnamesQuantile\n",
    "\n",
    "quantilesDf = (quantilesDf.T * np.array(scalingList)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23175ac0-b5ff-4d51-b9bc-c1d297c7a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resDf = generateFinalOutput(dataOriginal = data, \n",
    "                            dataDecisions = quantilesDf, \n",
    "                            targetVariable = 'demand', \n",
    "                            mergeOn = None, \n",
    "                            variablesToAdd = ['dayIndex', 'scalingValue'], \n",
    "                            scaleBy = 'scalingValue', \n",
    "                            includeTraining = False, \n",
    "                            sortBy = ['id', 'dayIndex'],\n",
    "                            longFormat = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "374f1c5f-1df6-4a63-ab7e-ecb878e059a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "costsPerID, costsPerSL = getCostsNV(resDf = resDf,\n",
    "                                    costsPerID_SAA = costsPerID_SAA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d31a5da8-89b5-4e8b-831e-cd6dedf5ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log(costsPerSL)\n",
    "\n",
    "with decisionArtifact.new_file(\"SAA_global.pkl\", mode = \"wb\") as file:\n",
    "    resDf.to_pickle(file)\n",
    "    \n",
    "with costArtifact.new_file(\"SAA_global.pkl\", mode = \"wb\") as file:\n",
    "    costsPerID.to_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31801030-cdc6-43f0-a381-5a881ac2c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log_artifact(decisionArtifact)\n",
    "wandb.log_artifact(costArtifact)\n",
    "    \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee27a9-4b17-4fe2-b4bf-87b47500d2fa",
   "metadata": {},
   "source": [
    "## LSx Standard - LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c08073b-9822-4494-aac2-090506124860",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatorName = 'LGBM'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5671047-039a-4206-b3fe-50a7dccb168d",
   "metadata": {},
   "source": [
    "### weightsByDistance = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbf82fd-1433-4d93-bd6a-31e9eefcc67f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)\n"
     ]
    }
   ],
   "source": [
    "weightsByDistance = False\n",
    "model = 'LSx'\n",
    "\n",
    "LSKDEx = LevelSetKDEx(estimator = estimatorLGBM,\n",
    "                      weightsByDistance = weightsByDistance)\n",
    "\n",
    "#---\n",
    "\n",
    "for combinedCV in (False, True):\n",
    "    tunePredictSave(quantileEstimator = LSKDEx,\n",
    "                    combinedCV = combinedCV,\n",
    "                    model = model,\n",
    "                    estimatorName = estimatorName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa4a46-f82b-4dff-9971-94c2f57e9f54",
   "metadata": {},
   "source": [
    "### weightsByDistance = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190ced3a-4634-4e87-a20e-9d702ab72ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsByDistance = True\n",
    "model = 'LSx_distWeights'\n",
    "\n",
    "LSKDEx = LevelSetKDEx(estimator = estimatorLGBM,\n",
    "                      weightsByDistance = weightsByDistance)\n",
    "\n",
    "#---\n",
    "\n",
    "for combinedCV in (False, True):\n",
    "    tunePredictSave(quantileEstimator = LSKDEx,\n",
    "                    combinedCV = combinedCV,\n",
    "                    model = model,\n",
    "                    estimatorName = estimatorName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21a54f4-65bd-41a7-b29e-0793bc06d948",
   "metadata": {},
   "source": [
    "## LSx Standard - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94663af6-7959-44b0-862b-a2aca7d817e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatorName = 'RF'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d9fba-b996-4429-b1c3-7e08acdd6130",
   "metadata": {},
   "source": [
    "### weightsByDistance = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca33ef51-89b0-46e8-a352-a79fa5bcd0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsByDistance = False\n",
    "model = 'LSx'\n",
    "\n",
    "LSKDEx = LevelSetKDEx(estimator = estimatorRF,\n",
    "                      weightsByDistance = weightsByDistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a57988-8a2b-4ca1-ba86-e53f7a12a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunePredictSave(quantileEstimator = LSKDEx,\n",
    "                combinedCV = False,\n",
    "                model = model,\n",
    "                estimatorName = estimatorName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e40fa-8a25-494d-b6c6-1dc1562f7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunePredictSave(quantileEstimator = LSKDEx,\n",
    "                combinedCV = True,\n",
    "                model = model,\n",
    "                estimatorName = estimatorName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a4897e-3089-491e-8236-bda8b0028504",
   "metadata": {},
   "source": [
    "### weightsByDistance = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1f0c067-e40f-49ca-a134-46ac7af815b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsByDistance = True\n",
    "model = 'LSx_distWeights'\n",
    "\n",
    "LSKDEx = LevelSetKDEx(estimator = estimatorRF,\n",
    "                      weightsByDistance = weightsByDistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339c7af-c0e8-4c58-a4e3-1b9bebaa6a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunePredictSave(quantileEstimator = LSKDEx,\n",
    "                combinedCV = False,\n",
    "                model = model,\n",
    "                estimatorName = estimatorName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9459b399-a805-4979-a8d8-d8d9d56b1f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunePredictSave(quantileEstimator = LSKDEx,\n",
    "                combinedCV = True,\n",
    "                model = model,\n",
    "                estimatorName = estimatorName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96650e8-677c-47ee-bbf2-9beca9562bdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LSx NN - LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e926c543-740a-4511-bf6f-de8d5b0a4a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatorName = 'LGBM'\n",
    "model = 'LSx_NN'\n",
    "weightsByDistance = True\n",
    "\n",
    "LSKDEx = LevelSetKDEx_NN(estimator = estimatorLGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d55e1a-9b44-4b19-a6dd-8f1ea5b43309",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunePredictSave(quantileEstimator = LSKDEx,\n",
    "                    combinedCV = False,\n",
    "                    model = model,\n",
    "                    estimatorName = estimatorName)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93177fc-6410-4df8-960e-301c56364a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunePredictSave(quantileEstimator = LSKDEx,\n",
    "                    combinedCV = True,\n",
    "                    model = model,\n",
    "                    estimatorName = estimatorName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee37e3f-531c-42f6-8873-7c8513ba1cfb",
   "metadata": {},
   "source": [
    "## RF WSAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1436eeb1-7d11-43b0-b302-99fac7423857",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatorName = 'RF'\n",
    "model = 'WSAA'\n",
    "weightsByDistance = False\n",
    "\n",
    "RFWSAA = RandomForestWSAA()\n",
    "\n",
    "#---\n",
    "\n",
    "tunePredictSave(quantileEstimator = RFWSAA,\n",
    "                combinedCV = False,\n",
    "                model = model,\n",
    "                estimatorName = estimatorName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f0450f-b2a0-4cee-ad6a-b79791a28dc9",
   "metadata": {},
   "source": [
    "## RF WSAA - No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5dda2da-b326-4560-bd72-45dc9904a56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/d3wue/modellingM5/runs/3nv1jfzk?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe30d4cfb80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'isModellingRun': True,\n",
    "          'model': \"WSAA\",\n",
    "          'estimator': \"RF\",\n",
    "          'weightsByDistance': False,\n",
    "          'combinedCV': False,\n",
    "          'kFolds': kFolds,\n",
    "          'nIter': nIter}\n",
    "    \n",
    "wandb.init(project = project, name = \"RF_standard\", job_type = \"modelling\", config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3752a683-0422-42df-a5f0-7da89ea41a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFWSAA = RandomForestWSAA(**paramsRF)\n",
    "\n",
    "RFWSAA.fit(X = XTrain, y = yTrain)\n",
    "\n",
    "quantilesDf = RFWSAA.predict(X = XTest, \n",
    "                             probs = probs, \n",
    "                             outputAsDf = True, \n",
    "                             scalingList = scalingList)\n",
    "\n",
    "quantilesDf.columns = colnamesQuantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa0fa6cf-4cb7-4df4-817b-99d86278432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resDf = generateFinalOutput(dataOriginal = data, \n",
    "                            dataDecisions = quantilesDf, \n",
    "                            targetVariable = 'demand', \n",
    "                            mergeOn = None, \n",
    "                            variablesToAdd = ['dayIndex', 'scalingValue'], \n",
    "                            scaleBy = 'scalingValue', \n",
    "                            includeTraining = False, \n",
    "                            sortBy = ['id', 'dayIndex'],\n",
    "                            longFormat = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d5848bc-3083-463c-a914-4b5530deb062",
   "metadata": {},
   "outputs": [],
   "source": [
    "costsPerID, costsPerSL = getCostsNV(resDf = resDf,\n",
    "                                    costsPerID_SAA = costsPerID_SAA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31d4799e-299a-4667-8b4d-0f4ce7fe40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log(costsPerSL)\n",
    "\n",
    "updateArtifact(name = 'decisionData',\n",
    "               dataToAdd = resDf,\n",
    "               fileNameToAdd = 'RF_standard')\n",
    "    \n",
    "updateArtifact(name = 'costData',\n",
    "               dataToAdd = costsPerID,\n",
    "               fileNameToAdd = 'RF_stanard') \n",
    "    \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90d0be-323f-4e3f-9880-cd419a3cdd94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dddex",
   "language": "python",
   "name": "dddex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
